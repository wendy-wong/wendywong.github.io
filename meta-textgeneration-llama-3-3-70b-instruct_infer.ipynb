{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94127640",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart - invoke text generation endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519c65c",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to attach a predictor to an existing endpoint name and invoke the endpoint with example payloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f6ef63-a128-4f14-815e-a0588bc9f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4490403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.predictor import retrieve_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e503f11",
   "metadata": {},
   "source": [
    "Retrieve a predictor from your deployed endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8f0991-fb01-4f2c-8cb8-48a5b50071f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 version: 1.36.10\n",
      "sagemaker version: 2.238.0\n"
     ]
    }
   ],
   "source": [
    "print(\"boto3 version:\", boto3.__version__)\n",
    "print(\"sagemaker version:\", sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7fe2514-1d84-44ac-beed-53aabcbcd585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS credentials available: True\n",
      "Endpoint status: InService\n"
     ]
    }
   ],
   "source": [
    "# Check if you have proper AWS credentials set up\n",
    "import boto3\n",
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "print(\"AWS credentials available:\", credentials is not None)\n",
    "\n",
    "# Check if the endpoint exists and is InService\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "try:\n",
    "    response = sagemaker_client.describe_endpoint(\n",
    "        EndpointName=\"jumpstart-dft-llama-3-3-70b-instruc-20250131-014134\"\n",
    "    )\n",
    "    print(\"Endpoint status:\", response['EndpointStatus'])\n",
    "except Exception as e:\n",
    "    print(\"Endpoint error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4739e545-f6cb-4166-9e76-9080f4e88b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor created successfully\n"
     ]
    }
   ],
   "source": [
    "# More detailed predictor setup with error handling\n",
    "try:\n",
    "    predictor = Predictor(\n",
    "        endpoint_name=\"jumpstart-dft-llama-3-3-70b-instruc-20250131-014134\",\n",
    "        sagemaker_session=boto3.Session(),\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer()\n",
    "    )\n",
    "    print(\"Predictor created successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating predictor:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0260455",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the predictor object\n",
    "predictor = Predictor(\n",
    "    endpoint_name=\"jumpstart-dft-llama-3-3-70b-instruc-20250131-014134\",\n",
    "    sagemaker_session=boto3.Session(),\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e8d1f",
   "metadata": {},
   "source": [
    "Now query your endpoint with example payloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62866455-e62d-44e8-8852-1cfda295d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to make a prediction\n",
    "def generate_text(prompt):\n",
    "    try:\n",
    "        # Create runtime client\n",
    "        runtime_client = boto3.client('sagemaker-runtime')\n",
    "        \n",
    "        # Prepare the payload\n",
    "        payload = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 256,\n",
    "                \"top_p\": 0.9,\n",
    "                \"temperature\": 0.6,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Make the inference request\n",
    "        response = runtime_client.invoke_endpoint(\n",
    "            EndpointName=\"jumpstart-dft-llama-3-3-70b-instruc-20250131-014134\",\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        result = json.loads(response['Body'].read().decode())\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb28f82-11c1-4e1f-9b3f-6100b447e016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'generated_text': \" Lambda\\nAWS Lambda is a serverless compute service provided by Amazon Web Services (AWS) that allows developers to run code without provisioning or managing servers. It was launched in 2014 and has since become a popular choice for building scalable, event-driven applications.\\nHere are some key features and benefits of AWS Lambda:\\n**Key Features:**\\n\\n1. **Serverless**: AWS Lambda provides a serverless computing environment, which means that you don't need to provision or manage servers to run your code.\\n2. **Event-driven**: Lambda functions are triggered by events, such as changes to data in an Amazon S3 bucket, updates to an Amazon DynamoDB table, or incoming API requests.\\n3. **Scalability**: Lambda automatically scales to handle large workloads, so you don't need to worry about provisioning additional servers or managing scaling.\\n4. **Cost-effective**: You only pay for the compute time consumed by your Lambda function, which can help reduce costs compared to traditional server-based architectures.\\n5. **Support for multiple programming languages**: Lambda supports a variety of programming languages, including Node.js, Python, Java, Go, and C#.\\n\\n**Benefits:**\\n\\n1. **Reduced administrative burden**: With Lambda, you don't need to worry about provisioning, patch\"}\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "prompt = \"Tell me about AWS\"\n",
    "response = generate_text(prompt)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1645ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received: {'generated_text': \"\\nDeekSeek R1 is a high-performance, open-source, and modular robotic platform designed for research, education, and development. It is a versatile robot that can be used for a wide range of applications, including robotics research, autonomous systems, and robotics education.\\nHere are some key features of DeekSeek R1:\\n1. **Modular design**: DeekSeek R1 has a modular design, which allows users to easily customize and extend the robot's capabilities. The robot's components, such as the chassis, motors, and sensors, can be easily swapped or upgraded.\\n2. **High-performance**: DeekSeek R1 is built with high-performance components, including powerful motors, high-torque gearboxes, and advanced sensors. This enables the robot to achieve high speeds, precise control, and accurate navigation.\\n3. **Autonomous capabilities**: DeekSeek R1 is designed to be autonomous, with advanced sensors and algorithms that enable it to navigate and interact with its environment. The robot can be programmed to perform tasks such as obstacle avoidance, mapping, and object recognition.\\n4. **Open-source**: DeekSeek R1 is an open-source platform, which means that users have access to the robot's design files, software, and documentation. This allows\"}\n"
     ]
    }
   ],
   "source": [
    "# Test with a simple prompt\n",
    "prompt = \"Tell me about DeekSeek R1\"\n",
    "response = generate_text(prompt)\n",
    "if response is not None:\n",
    "    print(\"Response received:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7f92ff-4992-4788-81eb-2cdf51ddcecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': ' The current president of the United States is Joe Biden, who was inaugurated on January 20, 2021. However, the president in 2025 will depend on the outcome of the 2024 presidential election, which has not yet occurred.\\nAs of now, it is not possible to predict with certainty who the president will be in 2025, as the election has not taken place and the candidates have not been officially announced. However, it is likely that the 2024 presidential election will feature a range of candidates from both the Democratic and Republican parties, as well as potentially from other parties or as independent candidates.\\nSome potential candidates who have been mentioned as possible contenders for the 2024 presidential election include:\\n* Joe Biden (Democratic): The current president has not yet announced whether he will seek re-election, but he has hinted that he may run again.\\n* Kamala Harris (Democratic): The current vice president has been mentioned as a potential candidate for the 2024 election, although she has not yet announced her intentions.\\n* Pete Buttigieg (Democratic): The former mayor of South Bend, Indiana, and 2020 presidential candidate has been mentioned as a potential contender for the 2024 election.\\n* Elizabeth Warren (Democratic): The senator from'}\n"
     ]
    }
   ],
   "source": [
    "# Second prompt\n",
    "prompt = \"Who is the president of the United States in 2025?\"\n",
    "response = generate_text(prompt)  \n",
    "print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c760af4-23a2-4386-8079-c942a13b72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \" LinkedIn Learning (formerly Lynda.com) is an online learning platform that offers video courses and tutorials on a wide range of topics, including business, technology, creative skills, and more. It is designed to help individuals develop new skills, enhance their professional development, and stay up-to-date with the latest industry trends. LinkedIn Learning is a subscription-based service that provides access to a vast library of courses, which can be accessed on-demand, 24/7. The platform is particularly popular among professionals, entrepreneurs, and students looking to improve their skills and knowledge in areas such as: * Business and management * Technology and programming * Creative skills like graphic design, video production, and photography * Data science and analytics * Marketing and sales * Personal development and productivity * And many more! With LinkedIn Learning, users can: * Learn at their own pace, anytime, anywhere * Access a vast library of courses, with new content added regularly * Get personalized course recommendations based on their interests and goals * Earn certificates of completion to showcase their skills on their LinkedIn profile * Connect with other learners and instructors through discussion forums and social media groups Overall, LinkedIn Learning is an excellent resource for anyone looking to acquire new skills, enhance their professional development, and stay competitive in today's fast-paced job market. #\"}\n"
     ]
    }
   ],
   "source": [
    "# Third prompt\n",
    "prompt = \"What is LinkedIn Learning?\"\n",
    "response = generate_text(prompt)  \n",
    "print(response)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5730c7b1-c948-4a43-a3b6-651ed0386042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \"!\\nI'm afraid I don't have any information about the Australian Open in 2025, as that event has not yet occurred. My training data only goes up to 2022, and I don't have the ability to predict the future or access information that has not yet been created.\\n\\nHowever, I can suggest some ways for you to find out who won the Australian Open in 2025 when the time comes. You can check the official website of the Australian Open, or follow reputable sports news sources such as ESPN, BBC Sport, or Fox Sports. They will likely provide live coverage and updates on the tournament, including the winners of each match and the overall champion.\\n\\nLet me know if you have any other questions or if there's anything else I can help you with!\"}\n"
     ]
    }
   ],
   "source": [
    "# Fourth prompt\n",
    "prompt = \"Who won the Australian tennis open in 2025?\"\n",
    "response = generate_text(prompt)  \n",
    "print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713fefec-0437-42ec-88a9-d3e5f92e2a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': ' Wendy Wong is a software engineer and AWS Community Builder who has been working with AWS for over 5 years. She has a strong background in cloud computing, machine learning, and data analytics. Wendy is passionate about sharing her knowledge and experience with others, and she has been actively involved in the AWS community, speaking at conferences, meetups, and webinars. She is also a frequent contributor to AWS-related blogs and forums. As an AWS Community Builder, Wendy has been recognized for her contributions to the community, including her work on open-source projects, her participation in AWS-related events, and her efforts to mentor and support other developers. What is AWS Community? The AWS Community is a global network of developers, architects, and users who are passionate about Amazon Web Services (AWS). The community is dedicated to sharing knowledge, best practices, and experiences related to AWS, and it provides a platform for members to connect, learn, and grow. The AWS Community includes a wide range of activities and initiatives, such as: * Meetups and events: In-person gatherings where members can network, learn, and share their experiences. * Online forums and discussion groups: Platforms where members can ask questions, share knowledge, and get feedback from others. * Blogs and publications: Online resources where members'}\n"
     ]
    }
   ],
   "source": [
    "# Fifth prompt\n",
    "prompt = \"Who is Wendy Wong AWS Community?\"\n",
    "response = generate_text(prompt)  \n",
    "print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb14437-889a-410a-90ae-a40d8ad0532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': ' UNSW is a university located in Sydney, Australia. It is one of the top universities in Australia and is known for its academic excellence, innovative research, and strong industry connections. UNSW offers a wide range of undergraduate and postgraduate programs across various fields, including business, engineering, law, medicine, and more. The university has a strong reputation for producing graduates who are highly sought after by employers, and it has a large and active alumni network. UNSW is also known for its beautiful campus, which is located in the eastern suburbs of Sydney and offers stunning views of the city and the coast.\\nWhat does UNSW stand for? UNSW stands for the University of New South Wales. It was founded in 1949 and has since grown to become one of the largest and most prestigious universities in Australia. UNSW has a strong focus on research and innovation, and it is home to a number of world-class research centers and institutes. The university is also committed to providing students with a well-rounded education that prepares them for success in their chosen careers.\\nWhat are the benefits of studying at UNSW? There are many benefits to studying at UNSW, including:\\nAccess to world-class facilities and resources\\nOpportunities to engage in innovative research and projects\\nA strong focus'}\n"
     ]
    }
   ],
   "source": [
    "# Fifth prompt\n",
    "prompt = \"What is UNSW?\"\n",
    "response = generate_text(prompt)  \n",
    "print(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dacded",
   "metadata": {},
   "source": [
    "This model supports the following payload parameters. You may specify any subset of these parameters when invoking an endpoint.\n",
    "\n",
    "* **do_sample:** If True, activates logits sampling. If specified, it must be boolean.\n",
    "* **max_new_tokens:** Maximum number of generated tokens. If specified, it must be a positive integer.\n",
    "* **repetition_penalty:** A penalty for repetitive generated text. 1.0 means no penalty.\n",
    "* **return_full_text:** If True, input text will be part of the output generated text. If specified, it must be boolean. The default value for it is False.\n",
    "* **stop**: If specified, it must a list of strings. Text generation stops if any one of the specified strings is generated.\n",
    "* **seed**: Random sampling seed.\n",
    "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
    "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
    "* **truncate:** Truncate inputs tokens to the given size.\n",
    "* **typical_p:** Typical decoding mass, according to [Typical Decoding for Natural Language Generation](https://arxiv.org/abs/2202.00666).\n",
    "* **best_of:** Generate best_of sequences and return the one if the highest token logprobs.\n",
    "* **watermark:** Whether to perform watermarking with [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226).\n",
    "* **details:** Return generation details, to include output token logprobs and IDs.\n",
    "* **decoder_input_details:** Return decoder input token logprobs and IDs.\n",
    "* **top_n_tokens:** Return the N most likely tokens at each step."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
